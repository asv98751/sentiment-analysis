 # The spark application is dockerzed and all the spark nodes alog with the master are running in the docker compose contianer.
 # can bereffered to the ..\docker-compose.yml

spark-master:
   image: manisekhar/twtanalysis:spkimg
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "4040:4040"
      - "9090:8080"
      - "7077:7077"
    networks:

 spark-worker-1:
    image: manisekhar/twtanalysis:spkimg
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
      SPARK_MASTER_URL: spark://spark-master:7077

  spark-worker-2:
    image: manisekhar/twtanalysis:spkimg
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
      SPARK_MASTER_URL: spark://spark-master:7077